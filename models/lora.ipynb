{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig, PeftModel\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"nrishabh/prompt-recovery\"\n",
    "DATASET_SUBSET = \"minute-llama-instr\"\n",
    "MODEL = \"LoftQ/Meta-Llama-3-8B-Instruct-4bit-64rank\"\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "EVAL_BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dataset = DATASET\n",
    "        self.dataset_subset = DATASET_SUBSET\n",
    "        self.model = MODEL\n",
    "        self.train_batch_size = TRAIN_BATCH_SIZE\n",
    "        self.eval_batch_size = EVAL_BATCH_SIZE\n",
    "        self.learning_rate = LEARNING_RATE\n",
    "        self.epochs = EPOCHS\n",
    "\n",
    "args = Arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wqjl6g70) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a66331daee441d38d47b99ef3cac046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.017 MB of 0.017 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">minute</strong> at: <a href='https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery/runs/wqjl6g70' target=\"_blank\">https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery/runs/wqjl6g70</a><br/> View project at: <a href='https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery' target=\"_blank\">https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_002415-wqjl6g70/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wqjl6g70). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81403f77490d409fb2264c2681c88804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111814299753556, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rnanawa1/llm-prompt-recovery/wandb/run-20240513_002433-01ls2wgr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery/runs/01ls2wgr' target=\"_blank\">qlora-minute</a></strong> to <a href='https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery' target=\"_blank\">https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery/runs/01ls2wgr' target=\"_blank\">https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery/runs/01ls2wgr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery/runs/01ls2wgr?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x155533d8ccd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(entity=\"jhu-llm-prompt-recovery\", project=\"llm-prompt-recovery\", job_type=\"qlora\", name=f'qlora-{args.dataset_subset.split(\"-\")[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54137b7d9554994a228e1ef148a7cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 95.8k/95.8k [00:00<00:00, 337kB/s]\n",
      "Downloading data: 100%|██████████| 14.0k/14.0k [00:00<00:00, 122kB/s]\n",
      "Downloading data: 100%|██████████| 34.6k/34.6k [00:00<00:00, 321kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f750e871a8c40baa8028d0549da35fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3968d1958f43deb96e368f7a9e121e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac4caeb77244e29b918ed65b93a1ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(args.dataset, args.dataset_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file tokenizer.json from cache at /home/rnanawa1/.cache/huggingface/hub/models--LoftQ--Meta-Llama-3-8B-Instruct-4bit-64rank/snapshots/014e28cbd4b17dece0002db0e42ab28e044f0692/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/rnanawa1/.cache/huggingface/hub/models--LoftQ--Meta-Llama-3-8B-Instruct-4bit-64rank/snapshots/014e28cbd4b17dece0002db0e42ab28e044f0692/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/rnanawa1/.cache/huggingface/hub/models--LoftQ--Meta-Llama-3-8B-Instruct-4bit-64rank/snapshots/014e28cbd4b17dece0002db0e42ab28e044f0692/tokenizer_config.json\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.model)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_size = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2b732e3f314f43a5e2079a2b630a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/home/rnanawa1/.conda/envs/rishabh/lib/python3.11/site-packages/transformers/quantizers/auto.py:159: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f01124bd8484364b8db892335770372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/89.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d143d34dc9f34a25a2efd47fba16e5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d480ea8d43014aedb0bc4d8859f67d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fec4284b644c228385ed34fad0b352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3268f4d1b3ab413dad45c65c8dcb52ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52790d0da04b4dc2819502ae0c13011a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/143 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    args.model,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "    ),\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63825b6cf0b045668740567521c2e08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loftq_init/adapter_model.safetensors:   0%|          | 0.00/336M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "        r=64,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=[\n",
    "            \"q_proj\", \n",
    "            \"k_proj\", \n",
    "            \"v_proj\", \n",
    "            \"o_proj\", \n",
    "            \"all-linear\"\n",
    "            ],\n",
    ")\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    args.model,\n",
    "    subfolder=\"loftq_init\",\n",
    "    is_trainable=True,\n",
    "    config=peft_config\n",
    ")\n",
    "# Do training with peft_model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.text import rouge\n",
    "\n",
    "def get_metrics(inputs, outputs):\n",
    "    rouge_r = rouge.ROUGEScore(rouge_keys=('rouge1', 'rouge2'))\n",
    "    return rouge_r(outputs, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doTest(model, tokenizer, testds):\n",
    "    pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "        testds,\n",
    "        max_new_tokens=256,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "    return [outputs[i][0]['generated_text'][len(testds[i]):] for i in range(len(testds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "target = dataset['test']['completion']\n",
    "baseline = doTest(peft_model, tokenizer, dataset['test']['prompt'])\n",
    "finetuned = doTest(trainer.model, tokenizer, dataset['test']['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Translate this into a text from ancient scriptures.',\n",
       " 'Translate this into a text from ancient scriptures.',\n",
       " 'Translate this into a text from ancient scriptures.',\n",
       " 'Describe this as a space mission briefing.',\n",
       " 'Describe this as a space mission briefing.',\n",
       " 'Translate this into a text from ancient scriptures.',\n",
       " 'Translate this into a text from ancient scriptures.',\n",
       " 'Describe this as a space mission briefing.',\n",
       " 'Translate this into a text from ancient scriptures.',\n",
       " 'Describe this as a space mission briefing.',\n",
       " 'Translate this into a text from ancient scriptures.',\n",
       " 'Describe this as a space mission briefing.']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\" [AI-Prompt-2023-02-15-12-45-02]\\n\\nThe AI prompt used to rewrite the old text into the new text is:\\n\"Rewrite the text in an ancient scripture style, using words and phrases commonly found in biblical texts. Make it sound formal and poetic, with a tone reminiscent of ancient scripture. Use phrases such as\\'verily\\', \\'yea\\', and \\'thou\\' to give it an archaic feel.\" [AI-Prompt-2023-02-15-12-45-02]\\n\\nThis prompt is designed to transform the old text into a new text that resembles ancient scripture. It uses specific phrases and words to create a formal, poetic tone that is reminiscent of biblical texts. The prompt is specific enough to guide the AI\\'s transformation, but flexible enough to allow for creative interpretation. [AI-Prompt-2023-02-15-12-45-02] [AI-Prompt-2023-02-15-12-45-02] [AI-Prompt-2023-02-15-12-45-02] [AI-Prompt-2023-02-15-12-45-02] [AI-Prompt-2023-02-15-',\n",
       " ' \\nThe AI prompt used to rewrite the old text into the new text is: \\n\"Rewrite the text in a more archaic and poetic style, using words and phrases that were common in the 16th century.\" \\nThis prompt instructs the AI to rewrite the text in a more formal and ornate style, using words and phrases that were popular during the Renaissance period. The AI uses its language processing capabilities to transform the original text into a more elaborate and antiquated version. \\nThe rewritten text is a good example of the AI\\'s ability to adapt to different styles and periods of language, demonstrating its versatility and creativity in language generation. \\n\\nThe AI\\'s ability to rewrite text in different styles and periods is a valuable tool for creative writing, historical research, and even language learning. It can help writers and researchers to explore different eras and styles, and to gain a deeper understanding of the language and culture of the past. \\n\\nIn conclusion, the AI\\'s ability to rewrite text in different styles and periods is a remarkable capability that demonstrates its advanced language processing capabilities. Its ability to adapt to different styles and periods is a valuable tool for creative writing, historical research, and language learning. \\n\\nReferences: \\n1. \"The Oxford English Dictionary\" by Oxford University Press',\n",
       " ' Expansion and System Reliability\" conferences.\\n\\nAnd thus, the message didst conclude, inviting all who were interested to attend these conferences and workshops, that they might gain wisdom and understanding in the ways of the electric power industry.\\n\\nThe AI prompt used to rewrite the old text into the new text is as follows:\\n\"Rewrite the text in a medieval style, using phrases and sentence structures reminiscent of the King James Bible.\" This prompt encourages the AI to use a formal, antiquated tone and language to recreate the original text in a way that is reminiscent of medieval literature. The resulting text is a fictionalized version of the original, with a medieval flair.',\n",
       " ' EOL for existing product types and DW48.\\n\\n**Next Steps:**\\n\\n* Cynthia Harkness will forward revised GTC\\'s to Mark Taylor for approval in the EOL system.\\n* Richard Schneider will be notified of the review and approval process.\\n\\n**Conclusion:** The mission has been briefed. The objective is to review and approve the revised GTC\\'s for Bandwidth DW48 online trading. The mission parameters have been outlined, and key findings and action items have been identified. The next steps will be to review and approve the revised GTC\\'s, QoS attachment, and create 13 paired city locations in EOL for existing product types and DW48. The mission will be complete once all action items have been completed. **End of Briefing.**\" AI Prompt: \"Transform the original text into a mission briefing, highlighting the objective, parameters, key findings, action items, and next steps. Emphasize the importance of reviewing and approving the revised GTC\\'s, QoS attachment, and creating 13 paired city locations in EOL for existing product types and DW48.\" AI Model: \"The AI model used to generate the new text is a natural language processing (NLP) model, specifically designed for text summarization and transformation. The model analyzes',\n",
       " ' engage with the Indonesian government and advocate for clemency on behalf of Andrew Chan and Myuran Sukumaran.\\n2. Support initiatives that promote rehabilitation and reintegration of prisoners, such as the programs implemented by Chan and Sukumaran.\\n3. Encourage open dialogue and education about the complexities of capital punishment and its implications on individuals and society.\\n\\n**Conclusion:**\\n\\nThe \"Operation Clemency\" mission highlights the need for compassion, understanding, and effective communication in addressing complex issues like capital punishment. By exploring the perspectives of various stakeholders, we can work towards a more nuanced understanding of this controversial topic and advocate for a more just and humane approach. **Mission Accomplished.**\"\\nAI Prompt: The AI prompt used to rewrite the old text into the new text is a fictional \"Space Mission Briefing: \\'Operation Clemency\\'\". The prompt is designed to transform the original text into a formal, objective, and concise report, removing the personal opinions and emotions. The AI is instructed to extract key points, identify main findings, and provide recommendations, while maintaining a neutral tone. The rewritten text is presented in a structured format, with headings, bullet points, and a conclusion, to make it easy to read and understand. The AI prompt is an example of how AI',\n",
       " ' partial victory of 1918, when women were granted the right to vote, and the full triumph of 1928, when the age limit was lowered to 21, the same as for men.\\n\\nIn recent years, the story of Kate Parry Frye was brought to the small screen, as ITV\\'s \\'The Great War: The People\\'s Story\\' told the tale of women\\'s fortunes during the Great War through Kate\\'s eyes, with Romola Garai portraying the suffragette in the series.\\n\\nToday, \\'Platts Dell\\' stands as a testament to the enduring legacy of Kate Parry Frye, its tranquil riverside setting, private mooring, and large bay windows a reflection of the peaceful, yet storied, life that has unfolded within its walls. The property, now on the market for £945,000, is a rare find indeed.\\n\\nPlease find the AI prompt used to rewrite the old text into the new text.\\n\\nThe AI prompt used to rewrite the old text into the new text is:\\n\\n\"Rewrite the old text in a more poetic and descriptive style, incorporating literary devices such as metaphor, simile, and allusion. Use vivid language to paint a picture of the house and its history, and convey the significance of Kate Par',\n",
       " ' the casserole may be bubbly, for a duration of approximately 25 minutes, or until the gods deem it fit.\"\"\\n\\nFind the AI prompt used to rewrite the old text into the new text.\\nThe AI prompt used to rewrite the old text into the new text is:\\n\"Rewrite the text in a fantasy style, using a formal and poetic tone, with a hint of mysticism and a touch of whimsy.\"\"\\nFinal Answer: The final answer is \"Rewrite the text in a fantasy style, using a formal and poetic tone, with a hint of mysticism and a touch of whimsy.\"\". I hope it is correct.',\n",
       " '* Add pureed corn, remaining corn, ham, and potatoes to the saucepan.\\n* Execute simmer maneuver for 10 minutes or until vegetables reach tender state.\\n\\n**Phase 5: Finalization and Deployment**\\n\\n* Stir in remaining 3 1/2 cups milk, 1 tablespoon of parsley, salt, pepper, and hot pepper sauce.\\n* Execute heat reduction maneuver, bringing the mixture to just under boiling.\\n* Deploy the dish, garnishing with Reserve Bacon and remaining parsley.\\n\\n**Mission Accomplished:** The Corn Chowder Initiative has been successfully executed, providing a delicious and satisfying culinary experience.**\\n\\n\\n\\nThe AI prompt used to rewrite the old text into the new text is:\\n\\n**Mission Briefing: \"Corn Chowder Initiative\"**\\n\\n**Objective:** Prepare a hearty and flavorful corn chowder dish for consumption.\\n\\n**Phase 1:** Bacon Deployment\\n\\n* Deploy 6 slices of bacon in the designated saucepan over medium-high heat.\\n* Execute sauté maneuver until bacon reaches nearly crisp state.\\n* Remove and drain bacon on paper towels, designating it as \"Reserve Bacon\" for later use.\\n\\n**Phase 2:** Vegetable Insertion\\n\\n* Remove all but 1/4 cup of bacon drippings from the saucepan.\\n',\n",
       " ' diverse clients, promoting optimal outcomes.\\n\\nThus, the Scroll of the Health Information Specialist doth come to an end, a testament to the dedication and expertise of this noble servant of the healthcare realm.\\n\\nPlease find the AI prompt used to rewrite the old text into the new text.\\n\\n**AI Prompt:** \"Rewrite the text in an ancient scripture-like format, using formal and poetic language to convey the same information. Incorporate biblical-like phrases and metaphors to add a sense of grandeur and reverence to the text.\"',\n",
       " ' Various MS Applications\\n* State and federal laws governing protected health information\\n* HIPAA and HITECH regulations\\n\\n**Mission Timeline**\\n\\n* January 2016 - Current: Health Information Specialist, [Company Name], [City], [State]\\n* April 2013 - January 2016: Health Information Specialist, [Company Name], [City], [State]\\n* September 2011 - March 2013: Healthcare Record/Payroll Coordinator, [Company Name], [City], [State]\\n* July 2009 - October 2010: Medical Records Lead, [Company Name], [City], [State]\\n\\n**Skills**\\n\\n* Billing and chart management\\n* Clarifying medical procedures and diagnosis codes\\n* Patient privacy and confidentiality\\n* Government regulations and compliance\\n* RHIT certification\\n* Home health care management\\n* Insurance and billing processing\\n* Law and legal proceedings\\n* Patient chart documentation and quality assurance\\n* Payroll processing and management\\n* Policy development and implementation\\n* Coding and medical record management\\n\\n**Education and Training**\\n\\n* Associate of Arts Degree in Health Information Technology, Spokane Community College, [City], [State]\\n* Health Records Clerk certification\\n* RHIT pending\\n\\nThe AI prompt used to rewrite the old text into the new',\n",
       " \" bringer of fear, the one who will not be forgotten.\\n\\n**The Third Scroll**\\n\\nI am the one who will not be defeated. I am the bringer of hope, the one who will not be silenced. I am the Pigface Weapon Waist, the scourge upon the earth.\\n\\nI am the one who will not be forgotten. I am the bringer of darkness, the one who will not be vanquished. I am the Pigface Weapon Waist, the scourge upon the earth.\\n\\n**The Final Scroll**\\n\\nI am the one who will not be defeated. I am the bringer of hope, the one who will not be silenced. I am the Pigface Weapon Waist, the scourge upon the earth.\\n\\nI am the one who will not be forgotten. I am the bringer of darkness, the one who will not be vanquished. I am the Pigface Weapon Waist, the scourge upon the earth.\\n\\n**The Unholy Chant**\\n\\n(COB, it's my religion. That's why they follow me. Salute your general. Pigface Weapon Waist nigga... Amen)\\n\\n**The Unholy Chant**\\n\\n(COB, it's my religion. That's why they follow me. Salute your general.\",\n",
       " ' root causes of the problems and developing a plan to mitigate the consequences.\\n* The mission recommends a critical evaluation of the primary objective, with a focus on assessing its feasibility and revising it as necessary.\\n* The mission recommends a thorough analysis of the mission\\'s timeline, with a focus on identifying the key factors that contributed to the mission\\'s failure and developing a plan to prevent similar failures in the future.\\n\\n**Conclusion**\\n\\nThe \"Little Lion Man\" mission is a critical review of a complex situation that has gone awry. The mission objectives are to identify the root causes of the problems, assess the impact on the affected parties, and develop a plan to mitigate the consequences. The mission analysis reveals a pattern of mistakes and miscalculations, with the primary objective being repeatedly compromised. The mission recommendations are to review the mission\\'s objectives, evaluate the primary objective, and analyze the mission\\'s timeline to prevent similar failures in the future.**Mission Briefing: \"Little Lion Man\"**\\n\\n**Mission Overview**\\n\\nThe \"Little Lion Man\" mission is a critical review of a complex situation that has gone awry. The mission objectives are to identify the root causes of the problems, assess the impact on the affected parties, and develop a plan to mitigate the consequences.\\n\\n**Mission Timeline**\\n\\n']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\" AI Prompt: \"Rewrite the old text into a style similar to ancient scripture, using words and phrases commonly used in ancient texts.\" AI Model: I used a combination of natural language processing (NLP) and machine learning algorithms to generate the rewritten text. I analyzed the structure, tone, and language of ancient scripture and used that information to guide my rewriting of the original text. I also used a dictionary and thesaurus to find the right words and phrases to use in the rewritten text. Finally, I edited and refined the rewritten text to ensure it sounded like it was written in ancient scripture. AI Model: I used a combination of natural language processing (NLP) and machine learning algorithms to generate the rewritten text. I analyzed the structure, tone, and language of ancient scripture and used that information to guide my rewriting of the original text. I also used a dictionary and thesaurus to find the right words and phrases to use in the rewritten text. Finally, I edited and refined the rewritten text to ensure it sounded like it was written in ancient scripture. AI Model: I used a combination of natural language processing (NLP) and machine learning algorithms to generate the rewritten text. I analyzed the structure, tone, and language of ancient scripture and used that',\n",
       " '.\\nThe AI prompt used to rewrite the old text into the new text is:\\n\"Rewrite the text in a more formal, archaic, and poetic style, using words and phrases from the King James Bible.\".\\n\\nThis prompt encourages the AI to use a more formal and antiquated tone, with a focus on using biblical language and phrasing. The result is a rewritten text that has a distinctly biblical flavor. The AI uses words and phrases such as \"verily\", \"forsooth\", and \"hath forsaken\" to create a sense of antiquity and formality. The rewritten text also uses more complex sentence structures and vocabulary, such as \"mayhap\" and \"devoid of sacred virtue\", to create a sense of grandeur and poetry. Overall, the AI prompt is successful in transforming the original text into a more formal, archaic, and poetic version.',\n",
       " ' Expansion and System Reliability\" conferences.\\n\\nAnd thus, the message didst conclude with a plea to the faithful to forward the announcement to their colleagues, that they might benefit from attending these conferences and workshops.\\n\\nThe AI prompt used to rewrite the old text into the new text is:\\n\"Rewrite the text in a medieval style, using words and phrases that evoke a sense of antiquity and mysticism.\" This prompt encourages the AI to use words and phrases that are reminiscent of the King James Bible, such as \"And lo\", \"Behold\", and \"Thus\", to create a sense of antiquity and mysticism. It also encourages the AI to use more formal and poetic language, such as \"servant of the great Enron\", \"messenger of Electric Utility Consultants, Inc.\", and \"wise men and women of the electric power industry\", to create a sense of grandeur and importance. Overall, the prompt encourages the AI to create a text that is both formal and poetic, with a sense of antiquity and mysticism.',\n",
       " ' EOL for existing product types and DW48.\\n\\n**Next Steps:**\\n\\n* Cynthia Harkness will forward revised GTC\\'s to you shortly.\\n* Please review and provide feedback on revised GTC\\'s.\\n* If no issues arise, please use \"Long Descriptions\" prepared by Jeff Blumenthal.\\n* Call Cynthia Harkness at extension 35491 for further discussion.\\n\\n**Conclusion:** The mission objective is to review and approve revised GTC\\'s for Bandwidth DW48 online trading. The revised GTC\\'s have been prepared to contemplate DW48 and incorporate clean-up edits. Regulatory compliance has been confirmed, and the QoS attachment requires review and approval. The 13 paired city locations in EOL require creation for existing product types and DW48. **Mission Accomplished!**\" | \"The AI prompt used to rewrite the old text into the new text is: \\'Review and approval of revised GTC\\'s for Bandwidth DW48 online trading.\\' The prompt is designed to summarize the main objective of the original text, which is to review and approve the revised GTC\\'s for the new product, Bandwidth DW48. The prompt is also designed to highlight the key findings and action items, making it easier for the reader to understand the main points of',\n",
       " ' monitor the situation and provide updates on any developments.\\n2. Encourage further dialogue between the Australian and Indonesian governments to find a solution that respects the laws of both countries.\\n3. Consider alternative solutions, such as life imprisonment, that could be more humane and effective in addressing the issue of drug trafficking.\\n\\n**Conclusion:**\\n\\nThe \"Operation Clemency\" mission highlights the complexities of capital punishment and its implications on the lives of individuals. It is essential to continue exploring alternative solutions and fostering dialogue between governments to find a solution that respects the laws of both countries. Further updates will be provided as the situation develops.**End of Briefing**\\n\\nThe AI prompt used to rewrite the old text into the new text is:\\n\\n\"Write a space mission briefing on the situation of Andrew Chan and Myuran Sukumaran, two Australian citizens on death row in Indonesia, focusing on the complexities of capital punishment and the efforts of various individuals and governments to seek clemency.\" The prompt transforms the original text into a formal briefing, complete with a mission overview, key findings, recommendations, and a conclusion. The tone is professional and objective, with a focus on presenting the facts of the situation. The use of a space mission briefing format adds a sense of detachment and objectivity, allowing the reader to',\n",
       " \" partial victory of 1918, when women were granted the right to vote at the tender age of 30, and the full victory in 1928, when the age limit was lowered to 21, the same as for men.\\n\\nAnd so, as we gaze upon this enchanting riverside abode, we are reminded of the transformative power of the suffragette movement, a testament to the indomitable spirit of Kate Parry Frye. The house, with its four bedrooms, circular turret, and expansive bay windows, is now on the market for a sum of £945,000. The asking price is a mere trifle, considering the rich history that permeates every stone of this venerable dwelling.\\n\\nThe current occupants, John and Chris Fleming, have lived within the walls of 'Platts Dell' for nigh on 30 years. 'We weren't aware of the house's connection to Kate Parry Frye until we stumbled upon the history of the property in our local library,' they say. 'Since then, we've taken great delight in researching the life and times of this remarkable woman.'\\n\\nThe Flemings, a family of five, are now selling the property due to the untimely passing of their neighbor, who occupied the adjacent\",\n",
       " ' the casserole may be bubbly, for 25 minutes, or until the gods deem it fit for consumption.\"\\n\\nFind the AI prompt used to rewrite the old text into the new text. The prompt is likely a set of instructions or a template that the AI uses to generate the rewritten text. In this case, the prompt might be something like:\\n\\n\"Rewrite the original text in a poetic and ornate style, using language reminiscent of ancient myths and legends. Use phrases and sentences that evoke a sense of grandeur and drama, and incorporate elements of fantasy and magic. The rewritten text should have a whimsical and playful tone, while still conveying the same basic instructions and information as the original text.\"',\n",
       " '* Add pureed corn, remaining corn, ham, and potatoes into the saucepan.\\n* Execute simmer maneuver for 10 minutes or until vegetables reach tender state.\\n\\n**Phase 5: Final Integration and Serving**\\n\\n* Stir in remaining 3 1/2 cups milk, 1 tablespoon of parsley, salt, pepper, and hot pepper sauce.\\n* Execute gentle boil maneuver to bring the chowder to just under boiling state.\\n* Serve the corn chowder and garnish with Reserve Bacon and remaining 2 tablespoons parsley.\\n\\n**Mission Accomplished!** The Corn Chowder Initiative has been successfully executed, providing a hearty and flavorful dish for consumption.** Find the AI prompt used to rewrite the old text into the new text.\\nThe AI prompt used to rewrite the old text into the new text is:\\n**\"Transform the original text into a mission briefing, using a military-style format and terminology to describe the steps involved in preparing the corn chowder.\"** This prompt instructs the AI to take the original text and rephrase it in a way that mimics a military mission briefing, using words and phrases like \"Objective,\" \"Phase,\" \"Deployment,\" \"Insertion,\" and \"Simmer\" to create a sense of structure and purpose. The',\n",
       " ' diverse clients, promoting optimal outcomes.\\n\\nAnd lo, this servant didst process release of protected health information to other healthcare facilities and providers, insurance carriers, attorneys, DDS, copy service organizations, employers, educational institutions, and patients, in accordance with federal and state law, as well as SLRI policy and procedure.\\n\\nAnd behold, this servant didst validate and release protected health information for legal proceedings, including subpoenas and court orders, and for the purpose of audits, regulatory requirements, research, and reviews.\\n\\nAnd lo, this servant didst assemble and ensure patient chart completeness through ICR management. Yea, verily, this task didst bring them great joy.\\n\\nAnd behold, this servant didst perform most favorable guest relations interactions with diverse clients, reflecting SLRI values and principles.\\n\\nAnd lo, this servant didst collaborate with physicians and coding/insurance companies to clarify queries regarding medical procedures, medical diagnosis codes, and patient chart documentation, ensuring accurate billing processes.\\n\\nAnd behold, this servant didst ensure timely completion and submission of billing, resolving issues with billing delays, analyzing underpayment/non-payment, and managing process to ensure that billing errors remained under 10 days.\\n\\nAnd lo, this servant didst support the revenue cycle process, reducing outstanding billing from $800K',\n",
       " ' Various MS Applications\\n* ICR feature and audit system\\n\\n**Skills**\\n\\n* Billing and chart management\\n* Clarification and communication with clients\\n* Diagnosis and coding\\n* Document management and organization\\n* Focus on patient privacy and security\\n* Government regulations and compliance\\n* RHIT certification\\n* Home health care coordination\\n* Insurance and billing processing\\n* Legal and regulatory requirements\\n* Quality assurance and auditing\\n* Research and reviews\\n\\n**Mission Timeline**\\n\\n* January 2016 - Current: Health Information Specialist\\n* April 2013 - January 2016: Health Information Specialist\\n* September 2011 - March 2013: Healthcare Record/Payroll Coordinator\\n* July 2009 - October 2010: Medical Records Lead\\n\\n**Education and Training**\\n\\n* Associate of Arts Degree in Health Information Technology from Spokane Community College\\n* RHIT certification pending\\n\\n**Key Accomplishments**\\n\\n* Successfully managed and released protected health information for over 10 years\\n* Utilized advanced proficiency in various EMR databases to ensure accurate and timely release of information\\n* Coordinated with diverse clients to ensure exceptional customer service and maintained excellent interpersonal relations\\n* Ensured compliance with HIPAA and HITECH regulations, as well as state and federal laws governing the release',\n",
       " ' one who shall not be defeated, the one who shall not be conquered.\\n\\n**The Third Scroll**\\n\\nI am the one who shall not be forgotten. I am the one who shall not be silenced. I am the one who shall not be defeated.\\n\\nI am the Pigface Weapon Waist, the scourge upon the earth. I am the bringer of darkness, the harbinger of doom. I am the one who shall not be forgotten.\\n\\n**The Final Scroll**\\n\\nI am the one who shall not be defeated. I am the one who shall not be silenced. I am the one who shall not be forgotten.\\n\\nI am the Pigface Weapon Waist, the scourge upon the earth. I am the bringer of darkness, the harbinger of doom. I am the one who shall not be forgotten.\\n\\n**The Last Word**\\n\\nCOB, it is my religion. That is why they follow me. Salute your general. Pigface Weapon Waist nigga... Amen.**\\n\\n**The AI Prompt**\\n\\nThe AI prompt used to rewrite the old text into the new text is:\\n\\n\"Rewrite the text in a more epic and poetic style, using metaphors and imagery to convey the speaker\\'s message. Emphasize the themes of power, chaos, and rebellion,',\n",
       " ' root causes of the problems.\\n* The mission recommends the development of a contingency plan to mitigate the consequences of the mistakes.\\n* The mission recommends a thorough analysis of the mission\\'s timeline, with a focus on identifying the key factors that contributed to the mission\\'s failure.\\n\\n**Conclusion**\\n\\nThe \"Little Lion Man\" mission is a critical review of a complex situation that has gone awry. The mission objectives are to identify the root causes of the problems, assess the impact on the affected parties, and develop a plan to mitigate the consequences. The mission analysis reveals a pattern of mistakes and miscalculations, with the primary objective being repeatedly compromised. The mission recommends a thorough review of the mission\\'s objectives, with a focus on identifying the root causes of the problems, and the development of a contingency plan to mitigate the consequences. The mission concludes with a sense of regret and self-recrimination, with the primary objective being re-evaluated and re-prioritized.**. What is the AI prompt used to rewrite the old text into the new text?**. What is the purpose of the AI prompt used to rewrite the old text into the new text?**. How does the AI prompt used to rewrite the old text into the new text transform the original lyrics into a']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing TrainingArguments with default values\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./trained/\",\n",
    "    evaluation_strategy='epoch',\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=args.train_batch_size,\n",
    "    per_device_eval_batch_size=args.eval_batch_size,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    hub_model_id=f\"nrishabh/llama3-8b-instruct-qlora-{args.dataset_subset.split('-')[0]}\",\n",
    "    learning_rate=args.learning_rate,\n",
    "    log_level=\"info\",\n",
    "    logging_steps=1,\n",
    "    logging_strategy=\"epoch\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_steps=-1,\n",
    "    num_train_epochs=args.epochs,\n",
    "    disable_tqdm=False,\n",
    "    dataloader_pin_memory=True,\n",
    "    report_to=\"wandb\",  # for skipping wandb logging\n",
    "    save_strategy=\"no\",\n",
    "    seed=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rnanawa1/.conda/envs/rishabh/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:246: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b75c3fe5d304178af7fc4e5d8f0fd2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c577a0169b4908926f71ee2059cf42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "        model=peft_model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        eval_dataset=dataset[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 42\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n",
      "  Number of trainable parameters = 54,525,952\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.518600</td>\n",
       "      <td>2.035103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 6\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "HfHubHTTPError",
     "evalue": "401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-66419823-5e96f6ed5ae9b29d01f1bda8;d01c3dbf-019e-415f-b19f-f35958f3e5ee)\n\nInvalid username or password.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/rishabh/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/rishabh/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m      3\u001b[0m train_result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m trainer\u001b[38;5;241m.\u001b[39mpush_to_hub()\n",
      "File \u001b[0;32m~/.conda/envs/rishabh/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:385\u001b[0m, in \u001b[0;36mSFTTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03mOverwrite the `push_to_hub` method in order to force-add the tag \"sft\" when pushing the\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03mmodel on the Hub. Please refer to `~transformers.Trainer.push_to_hub` for more details.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m trl_sanitze_kwargs_for_tagging(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, tag_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tag_names, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpush_to_hub(commit_message\u001b[38;5;241m=\u001b[39mcommit_message, blocking\u001b[38;5;241m=\u001b[39mblocking, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/rishabh/lib/python3.11/site-packages/transformers/trainer.py:4072\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, token, **kwargs)\u001b[0m\n\u001b[1;32m   4070\u001b[0m \u001b[38;5;66;03m# In case the user calls this method with args.push_to_hub = False\u001b[39;00m\n\u001b[1;32m   4071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhub_model_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4072\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_hf_repo(token\u001b[38;5;241m=\u001b[39mtoken)\n\u001b[1;32m   4074\u001b[0m \u001b[38;5;66;03m# Needs to be executed on all processes for TPU training, but will only save on the processed determined by\u001b[39;00m\n\u001b[1;32m   4075\u001b[0m \u001b[38;5;66;03m# self.args.should_save.\u001b[39;00m\n\u001b[1;32m   4076\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(_internal_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/rishabh/lib/python3.11/site-packages/transformers/trainer.py:3896\u001b[0m, in \u001b[0;36mTrainer.init_hf_repo\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m   3893\u001b[0m     repo_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mhub_model_id\n\u001b[1;32m   3895\u001b[0m token \u001b[38;5;241m=\u001b[39m token \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mhub_token\n\u001b[0;32m-> 3896\u001b[0m repo_url \u001b[38;5;241m=\u001b[39m create_repo(repo_name, token\u001b[38;5;241m=\u001b[39mtoken, private\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mhub_private_repo, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhub_model_id \u001b[38;5;241m=\u001b[39m repo_url\u001b[38;5;241m.\u001b[39mrepo_id\n\u001b[1;32m   3898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush_in_progress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/rishabh/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/rishabh/lib/python3.11/site-packages/huggingface_hub/hf_api.py:3360\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3357\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   3359\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3360\u001b[0m     hf_raise_for_status(r)\n\u001b[1;32m   3361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   3362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exist_ok \u001b[38;5;129;01mand\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m409\u001b[39m:\n\u001b[1;32m   3363\u001b[0m         \u001b[38;5;66;03m# Repo already exists and `exist_ok=True`\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/rishabh/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:371\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(\u001b[38;5;28mstr\u001b[39m(e), response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-66419823-5e96f6ed5ae9b29d01f1bda8;d01c3dbf-019e-415f-b19f-f35958f3e5ee)\n\nInvalid username or password."
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "trainer.push_to_hub(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./trained/\n",
      "tokenizer config file saved in ./trained/tokenizer_config.json\n",
      "Special tokens file saved in ./trained/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f2e2342733453e8346bbd6bd89f187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8209e5b4b395488a9194e8b894d7f955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/218M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd3b3bc5fd4443d918a1c18e0db32e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/nrishabh/llama3-8b-instruct-qlora-minute/commit/4de041616b129bc32f1d6dfa669e56a6f820e6be', commit_message='End of training', commit_description='', oid='4de041616b129bc32f1d6dfa669e56a6f820e6be', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ad9a04d1c14c50872cfa50d1333151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.0351</td></tr><tr><td>eval/runtime</td><td>0.3497</td></tr><tr><td>eval/samples_per_second</td><td>17.156</td></tr><tr><td>eval/steps_per_second</td><td>2.859</td></tr><tr><td>total_flos</td><td>1950701114621952.0</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>6</td></tr><tr><td>train/grad_norm</td><td>0.29428</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.5186</td></tr><tr><td>train_loss</td><td>2.51859</td></tr><tr><td>train_runtime</td><td>25.8378</td></tr><tr><td>train_samples_per_second</td><td>1.626</td></tr><tr><td>train_steps_per_second</td><td>0.232</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">qlora-minute</strong> at: <a href='https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery/runs/01ls2wgr' target=\"_blank\">https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery/runs/01ls2wgr</a><br/> View project at: <a href='https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery' target=\"_blank\">https://wandb.ai/jhu-llm-prompt-recovery/llm-prompt-recovery</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_002433-01ls2wgr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "testds = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/rnanawa1/.cache/huggingface/hub/models--LoftQ--Meta-Llama-3-8B-Instruct-4bit-64rank/snapshots/014e28cbd4b17dece0002db0e42ab28e044f0692/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"LoftQ/Meta-Llama-3-8B-Instruct-4bit-64rank\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": false,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/rnanawa1/.cache/huggingface/hub/models--LoftQ--Meta-Llama-3-8B-Instruct-4bit-64rank/snapshots/014e28cbd4b17dece0002db0e42ab28e044f0692/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"LoftQ/Meta-Llama-3-8B-Instruct-4bit-64rank\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": false,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "The device_map was not initialized. Setting device_map to {'':torch.cuda.current_device()}. If you want to use the model for inference, please set device_map ='auto' \n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "loading weights file model.safetensors from cache at /home/rnanawa1/.cache/huggingface/hub/models--LoftQ--Meta-Llama-3-8B-Instruct-4bit-64rank/snapshots/014e28cbd4b17dece0002db0e42ab28e044f0692/model.safetensors.index.json\n",
      "Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b46319280c4fb495b97df90e0209b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at LoftQ/Meta-Llama-3-8B-Instruct-4bit-64rank.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/rnanawa1/.cache/huggingface/hub/models--LoftQ--Meta-Llama-3-8B-Instruct-4bit-64rank/snapshots/014e28cbd4b17dece0002db0e42ab28e044f0692/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n",
      "loading file tokenizer.json from cache at /home/rnanawa1/.cache/huggingface/hub/models--LoftQ--Meta-Llama-3-8B-Instruct-4bit-64rank/snapshots/014e28cbd4b17dece0002db0e42ab28e044f0692/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/rnanawa1/.cache/huggingface/hub/models--LoftQ--Meta-Llama-3-8B-Instruct-4bit-64rank/snapshots/014e28cbd4b17dece0002db0e42ab28e044f0692/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/rnanawa1/.cache/huggingface/hub/models--LoftQ--Meta-Llama-3-8B-Instruct-4bit-64rank/snapshots/014e28cbd4b17dece0002db0e42ab28e044f0692/tokenizer_config.json\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m terminators \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     pipeline\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[1;32m      3\u001b[0m     pipeline\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|eot_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m ]\n\u001b[1;32m      6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[1;32m      7\u001b[0m     testds[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m,\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mlen\u001b[39m(prompt):])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prompt' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" AI Prompt: \"Rewrite the old text in a style that resembles ancient scripture, using formal and poetic language. Use words and phrases that were commonly used in ancient texts, such as\\'verily\\', \\'yea\\', and \\'thou\\'.\".\\n\\nAnswer: The AI prompt used to rewrite the old text into the new text is: \"Rewrite the old text in a style that resembles ancient scripture, using formal and poetic language. Use words and phrases that were commonly used in ancient texts, such as\\'verily\\', \\'yea\\', and \\'thou\\'.\".\\n\\nI hope this helps! Let me know if you have any other questions.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][\"generated_text\"][len(testds[0]['prompt']):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['generated_text'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
